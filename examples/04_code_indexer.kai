#!/usr/bin/env kaish
# Example 4: Code Repository Indexer
# A real-world script that indexes a codebase for semantic search
# Demonstrates: VFS, scatter/gather, MCP tools, structured data flow

# --- Configuration ---
set REPO_PATH = "/src/myproject"        # VFS mount point
set INDEX_PATH = "/scratch/index"       # Output location
set CHUNK_SIZE = 1000                   # Tokens per chunk
set PARALLELISM = 8                     # Concurrent embedding calls

# --- Setup ---
mkdir ${INDEX_PATH}
echo "ğŸ“ Indexing ${REPO_PATH}..."

# --- Phase 1: Discover source files ---
# Find all code files, exclude generated/vendored
ls path=${REPO_PATH} recursive=true \
    | grep pattern="\.(rs|go|py|ts|js)$" \
    | grep invert=true pattern="(vendor|node_modules|target|dist)/" \
    > ${INDEX_PATH}/files.json

cat ${INDEX_PATH}/files.json | jq path="length"
set FILE_COUNT = ${?.out}
echo "Found ${FILE_COUNT} source files"

# --- Phase 2: Extract metadata in parallel ---
# For each file: parse AST, extract functions/classes/imports
cat ${INDEX_PATH}/files.json \
    | scatter as=FILE limit=${PARALLELISM} \
    | extract-symbols file=${FILE} \
    | gather progress=true \
    > ${INDEX_PATH}/symbols.json

echo "âœ… Extracted symbols from all files"

# --- Phase 3: Chunk files for embedding ---
# Split large files into overlapping chunks
cat ${INDEX_PATH}/files.json \
    | scatter as=FILE limit=${PARALLELISM} \
    | chunk-file file=${FILE} size=${CHUNK_SIZE} overlap=100 \
    | gather \
    | flatten \
    > ${INDEX_PATH}/chunks.json

cat ${INDEX_PATH}/chunks.json | jq path="length"
set CHUNK_COUNT = ${?.out}
echo "Created ${CHUNK_COUNT} chunks for embedding"

# --- Phase 4: Generate embeddings via MCP ---
# This is the expensive part - parallelize carefully
cat ${INDEX_PATH}/chunks.json \
    | scatter as=CHUNK limit=${PARALLELISM} \
    | embeddings.embed text=${CHUNK.content} model="text-embedding-3-small" \
    | gather progress=true errors=${INDEX_PATH}/embed_errors.json \
    > ${INDEX_PATH}/embeddings.json

# Check for failures
cat ${INDEX_PATH}/embed_errors.json | jq path="length"
set ERROR_COUNT = ${?.out}
if (${ERROR_COUNT} > 0); then
    echo "âš ï¸  ${ERROR_COUNT} chunks failed to embed"
fi

# --- Phase 5: Build the index ---
# Combine everything into a searchable structure
build-index \
    symbols=${INDEX_PATH}/symbols.json \
    chunks=${INDEX_PATH}/chunks.json \
    embeddings=${INDEX_PATH}/embeddings.json \
    output=${INDEX_PATH}/index.db

echo "âœ… Index built at ${INDEX_PATH}/index.db"

# --- Phase 6: Generate summary stats ---
index-stats db=${INDEX_PATH}/index.db > ${INDEX_PATH}/stats.json
cat ${INDEX_PATH}/stats.json | format template="
ğŸ“Š Index Summary
   Files:      {files}
   Functions:  {functions}
   Classes:    {classes}
   Chunks:     {chunks}
   Size:       {size_mb}MB
"

# --- Bonus: Verify with a test query ---
echo "\nğŸ” Test query: 'error handling'"
search db=${INDEX_PATH}/index.db query="error handling" limit=3 \
    | format template="
  {score}: {file}:{line}
    {snippet}
"

echo "\nğŸ‰ Indexing complete!"
